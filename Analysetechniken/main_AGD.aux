\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Statistische Grundlagen}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Beschaffenheit von Daten}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Einfache deskriptive Statistik}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Qualifizierung der Tendenz insgesamt}{3}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Quantifizierung der Streuung der Daten}{4}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Boxplots}{4}{subsection.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Boxplot Beispiel}}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:boxplot}{{1}{4}{Boxplot Beispiel}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Histogramme}{5}{subsection.1.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Equi-Width Beispiel}}{5}{figure.caption.3}}
\newlabel{fig:equiWidth}{{2}{5}{Equi-Width Beispiel}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Equi-Width Beispiel}}{6}{figure.caption.4}}
\newlabel{fig:equiDepth}{{3}{6}{Equi-Width Beispiel}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Entropie}{6}{subsection.1.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Wahrscheinlichkeitstheorie}{6}{subsection.1.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schema Kontingenztabelle}}{7}{figure.caption.5}}
\newlabel{fig:contingency_ex}{{4}{7}{Schema Kontingenztabelle}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}Statistische Tests}{9}{subsection.1.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.1}Chi-Quadrat Unabh\IeC {\"a}ngigkeitstest}{9}{subsubsection.1.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.2}Kolmogorov-Smirnov-Test}{10}{subsubsection.1.9.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.3}Wilcoxon-Mann-Whitney Test}{10}{subsubsection.1.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.9.4}Bernoulli-Experiment}{11}{subsubsection.1.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10}Datenreduktion}{12}{subsection.1.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.10.1}Numerosity Reduction}{12}{subsubsection.1.10.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.10.2}Dimensionality Reduction}{13}{subsubsection.1.10.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Ein Beispiel Datenbestand mit Filmbewertungen von verschieden Personen.\relax }}{14}{table.caption.18}}
\newlabel{tab:svd_example}{{1}{14}{Ein Beispiel Datenbestand mit Filmbewertungen von verschieden Personen.\relax }{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Die Rohdaten als Heatmap.\relax }}{15}{figure.caption.19}}
\newlabel{fig:original_data}{{5}{15}{Die Rohdaten als Heatmap.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Die Heatmap f\IeC {\"u}r die Approximation mit reduzierten Daten.\relax }}{17}{figure.caption.20}}
\newlabel{fig:reduced_data}{{6}{17}{Die Heatmap für die Approximation mit reduzierten Daten.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.10.3}Diskretisierung}{17}{subsubsection.1.10.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Informatik Grundlagen}{19}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Indizierung allgemein}{19}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Indizierung Beispiel}}{19}{figure.caption.21}}
\newlabel{fig:index_example}{{7}{19}{Indizierung Beispiel}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}R\IeC {\"a}umliche Indexstrukturen}{20}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Normalisierung}{20}{subsubsection.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}k-dimensionale B\IeC {\"a}ume}{21}{subsubsection.2.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Objekte mit r\IeC {\"a}umlicher Ausdehnung}{21}{subsubsection.2.2.3}}
\newlabel{alg:NN}{{1}{22}{k-dimensionale Bäume}{algocf.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Algorithmus f\IeC {\"u}r eine NN-Anfrage mittels eines kDB-Baumes.\relax }}{22}{algocf.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Optimierung kd-B\IeC {\"a}ume}{23}{subsubsection.2.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces kdB-Baum}}{24}{figure.caption.23}}
\newlabel{fig:kdB_Tree}{{8}{24}{kdB-Baum}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}R-Baum}{24}{subsubsection.2.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces R-Baum 2D}}{25}{figure.caption.25}}
\newlabel{fig:r_tree}{{9}{25}{R-Baum 2D}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces R-Baum 3D}}{26}{figure.caption.26}}
\newlabel{fig:r_tree3D}{{10}{26}{R-Baum 3D}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Instanzbasiertes Lernen}{27}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Klassifikation mit Entscheidungsb\IeC {\"a}umen}{29}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Attribute vs. Features}{29}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Bin\IeC {\"a}re Entscheidungsb\IeC {\"a}ume}{29}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Entscheidungsbaum Beispiel}}{30}{figure.caption.27}}
\newlabel{fig:decision_tree}{{11}{30}{Entscheidungsbaum Beispiel}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Kosten beim Lernen}{31}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Beispiel Classifier}}{32}{figure.caption.28}}
\newlabel{fig:classifier_ex}{{12}{32}{Beispiel Classifier}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}NULL-Werte}{32}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Evaluation von Datenanalyseverfahren}{34}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Training und Testing}{34}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Wahrscheinlichkeiten als Vorhersageergebnis}{35}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Fehlerarten und entsprechende Ma\IeC {\ss }e}{36}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Bias vs. Varianz}{36}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Fehlerarten und Erfolgsquote}{36}{subsubsection.4.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Lift Charts}{37}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Quelle: \href  {http://www.saedsayad.com/model_evaluation_c.htm}{www.saesdsayad.com}\relax }}{37}{figure.caption.29}}
\newlabel{fig:lift}{{13}{37}{Quelle: \href {http://www.saedsayad.com/model_evaluation_c.htm}{www.saesdsayad.com}\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}ROC Kurven}{38}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces ROC Curve}}{38}{figure.caption.30}}
\newlabel{fig:roc}{{14}{38}{ROC Curve}{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Eine alternative Darstellung von erwartetem Fehler \(\epsilon \) im Verh\IeC {\"a}ltnis zur Wahrscheinlichkeit \(p[+]\), dass ein zuf\IeC {\"a}lliges Objekt zur Klasse \([+]\) geh\IeC {\"o}rt.\relax }}{40}{figure.caption.31}}
\newlabel{fig:alt}{{15}{40}{Eine alternative Darstellung von erwartetem Fehler \(\epsilon \) im Verhältnis zur Wahrscheinlichkeit \(p[+]\), dass ein zufälliges Objekt zur Klasse \([+]\) gehört.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Numeric Measures}}{41}{figure.caption.32}}
\newlabel{fig:numeric}{{16}{41}{Numeric Measures}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces MML}}{42}{figure.caption.33}}
\newlabel{fig:mml}{{17}{42}{MML}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Lineares Modell}}}{42}{figure.caption.33}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Polynomielles Modell}}}{42}{figure.caption.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Minimum Description Language}{42}{subsection.4.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Minimum Message Length}{42}{subsubsection.4.6.1}}
\citation{Witten11}
\@writefile{toc}{\contentsline {section}{\numberline {5}Association Rules}{46}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Apriori}{47}{subsection.5.1}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Apriori Algorithmus.\relax }}{48}{algocf.2}}
\newlabel{alg:apriori}{{2}{48}{Apriori}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Multidimensional Association Rules}{49}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Multi-Level Association Rules}{49}{subsection.5.3}}
\citation{Han95}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Beispiel einer Transaktionstabelle.\relax }}{50}{table.caption.35}}
\newlabel{tab:transaction}{{2}{50}{Beispiel einer Transaktionstabelle.\relax }{table.caption.35}{}}
\citation{Han95}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces 2-dimensionale Darstellung von Frequent Itemsets auf unterschiedlichen Abstraktionsebenen.\relax }}{51}{table.caption.36}}
\newlabel{tab:3}{{3}{51}{2-dimensionale Darstellung von Frequent Itemsets auf unterschiedlichen Abstraktionsebenen.\relax }{table.caption.36}{}}
\citation{Petersohn05}
\@writefile{toc}{\contentsline {section}{\numberline {6}Association Rules - Erweiterungen und Anwendungen}{53}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Direct Hashing and Pruning}{53}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Candidate Itemset Reduktion}{53}{subsubsection.6.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Datenbankreduktion}{53}{subsubsection.6.1.2}}
\citation{Park95}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}DHP Algorithmus}{54}{subsubsection.6.1.3}}
\citation{Toi96}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Sampling}{55}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Negative Border}{55}{subsubsection.6.2.1}}
\citation{Toi96}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Optimistische Verfeinerung}{56}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Frequent Pattern Trees}{57}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}FP-Tree Erzeugung}{57}{subsubsection.6.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Frequent Pattern Mining}{58}{subsubsection.6.4.2}}
\citation{Han00}
\citation{Witten11}
\@writefile{toc}{\contentsline {section}{\numberline {7}Pattern Mining unter Constraints}{60}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Constrained Association Rules}{60}{subsection.7.1}}
\citation{HanBOOK}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Meta-Rule Guided Mining}{61}{subsubsection.7.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}1-var und 2-var Constraints}{62}{subsubsection.7.1.2}}
\citation{Ng98}
\citation{Ng98}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Eigenschaften von Constraints}{63}{subsubsection.7.1.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Charakterisierung der Anti-Monotonizit\IeC {\"a}t und Succinctness von 1-var Constraints.\relax }}{64}{table.caption.37}}
\newlabel{tab:var_con}{{4}{64}{Charakterisierung der Anti-Monotonizität und Succinctness von 1-var Constraints.\relax }{table.caption.37}{}}
\citation{Garofalakis99}
\citation{Garofalakis99}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Constrained Frequent Sequence Mining}{65}{subsection.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Clustering}{67}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Partitionierendes Clustering}{70}{subsection.8.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}k-Means}{70}{subsubsection.8.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.2}k-Means in der Variante CLARANS}{71}{subsubsection.8.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3}BIRCH}{72}{subsubsection.8.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Hierarchisches Clustering}{74}{subsection.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Probleme mit hochdimensionalen R\IeC {\"a}umen}{76}{subsection.8.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Clustering mit kategorischen Daten}{77}{subsection.8.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Dichte-basiertes Clustering}{79}{subsection.8.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.5.1}DBSCAN}{79}{subsubsection.8.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.5.2}OPTICS}{80}{subsubsection.8.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.6}Probabilistisches Clustering}{82}{subsection.8.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.6.1}Expectation Maximization}{82}{subsubsection.8.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.6.2}Erweiterungen von Mixture Models}{83}{subsubsection.8.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Statistische Modellierung}{87}{section.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Naive Bayes}{87}{subsection.9.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Bayesian Networks}{88}{subsection.9.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces BN Beispiel}}{88}{figure.caption.38}}
\newlabel{fig:cpt}{{18}{88}{BN Beispiel}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces BN EM Beispiel}}{90}{figure.caption.39}}
\newlabel{fig:bnem}{{19}{90}{BN EM Beispiel}{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Anwendung Bayesian Networks: Duplikaterkennung}{90}{subsection.9.3}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Lineare Modelle und SVMs}{92}{section.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Logistic Regression}{92}{subsection.10.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Support Vector Machines}{93}{subsection.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Support Vector Regression}{95}{subsection.10.3}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Ensembles}{96}{section.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Bagging}{96}{subsection.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Boosting}{97}{subsection.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Stacking}{98}{subsection.11.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Interpretation von Ensembles}{98}{subsection.11.4}}
\bibstyle{plainnat}
\bibdata{agd}
\bibcite{Garofalakis99}{{1}{1999}{{Garofalakis et~al.}}{{Garofalakis, Rastogi, and Shim}}}
\bibcite{HanBOOK}{{2}{2005}{{Han}}{{}}}
\bibcite{Han95}{{3}{1995}{{Han and Fu}}{{}}}
\bibcite{Han00}{{4}{2000}{{Han et~al.}}{{Han, Pei, and Yin}}}
\bibcite{Ng98}{{5}{1998}{{Ng et~al.}}{{Ng, Lakshmanan, Han, and Pang}}}
\bibcite{Park95}{{6}{1995}{{Park et~al.}}{{Park, Chen, and Yu}}}
\bibcite{Petersohn05}{{7}{2005}{{Petersohn}}{{}}}
\bibcite{Toi96}{{8}{1996}{{Toivonen}}{{}}}
\bibcite{Witten11}{{9}{2011}{{Witten et~al.}}{{Witten, Frank, and Hall}}}
